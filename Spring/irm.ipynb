{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Dict\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Natural frequency\n",
    "omega_0 = 1.0\n",
    "\n",
    "# Time points\n",
    "t = jnp.linspace(0, 10, 100).reshape(-1, 1)\n",
    "\n",
    "def generate_oscillator_data(beta: float, key: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate time-series data for an underdamped harmonic oscillator.\n",
    "    \"\"\"\n",
    "    # Initial conditions\n",
    "    x0 = jax.random.uniform(key, minval=-1.0, maxval=1.0)\n",
    "    v0 = jax.random.uniform(key, minval=-1.0, maxval=1.0)\n",
    "\n",
    "    # Damped frequency\n",
    "    omega_d = jnp.sqrt(omega_0**2 - beta**2)\n",
    "\n",
    "    # Solution\n",
    "    A = x0\n",
    "    B = (v0 + beta * x0) / omega_d\n",
    "    x = jnp.exp(-beta * t) * (A * jnp.cos(omega_d * t) + B * jnp.sin(omega_d * t))\n",
    "\n",
    "    return {\n",
    "        't': t,\n",
    "        'x': x,\n",
    "        'beta': beta,\n",
    "        'x0': x0,\n",
    "        'v0': v0\n",
    "    }\n",
    "\n",
    "# Define multiple environments with different damping coefficients\n",
    "betas = [0.1, 0.2, 0.3]\n",
    "num_envs = len(betas)\n",
    "\n",
    "# Generate data for each environment\n",
    "env_data = []\n",
    "for beta in betas:\n",
    "    key, subkey = jax.random.split(key)\n",
    "    data = generate_oscillator_data(beta, subkey)\n",
    "    env_data.append(data)\n",
    "\n",
    "# Prepare data for training\n",
    "def prepare_data(env_data):\n",
    "    batch_data = []\n",
    "    for data in env_data:\n",
    "        x = data['t']\n",
    "        y = data['x']\n",
    "        beta = data['beta']\n",
    "        x0 = data['x0']\n",
    "        v0 = data['v0']\n",
    "        batch_data.append({'x': x, 'y': y, 'beta': beta, 'x0': x0, 'v0': v0})\n",
    "    return batch_data\n",
    "\n",
    "batch_data = prepare_data(env_data)\n",
    "\n",
    "# Define the model architecture\n",
    "def feature_extractor_fn(x):\n",
    "    phi = hk.Sequential([\n",
    "        hk.Linear(64), jax.nn.tanh,\n",
    "        hk.Linear(64), jax.nn.tanh\n",
    "    ])\n",
    "    return phi(x)\n",
    "\n",
    "def predictor_fn(features):\n",
    "    w = hk.Linear(1)\n",
    "    return w(features)\n",
    "\n",
    "# Transform the functions\n",
    "feature_extractor = hk.transform(feature_extractor_fn)\n",
    "predictor = hk.transform(predictor_fn)\n",
    "\n",
    "# Initialize parameters\n",
    "def init_model(key, x_sample):\n",
    "    key_phi, key_w = jax.random.split(key)\n",
    "    phi_params = feature_extractor.init(key_phi, x_sample)\n",
    "    features = feature_extractor.apply(phi_params, None, x_sample)\n",
    "    w_params = predictor.init(key_w, features)\n",
    "    return {'phi': phi_params, 'w': w_params}\n",
    "\n",
    "x_sample = batch_data[0]['x'][0:1]\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "params = init_model(subkey, x_sample)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# Loss functions\n",
    "def mse_loss(predictions, targets):\n",
    "    return jnp.mean((predictions - targets) ** 2)\n",
    "\n",
    "def compute_erm_loss(params, x, y):\n",
    "    features = feature_extractor.apply(params['phi'], None, x)\n",
    "    predictions = predictor.apply(params['w'], None, features)\n",
    "    return mse_loss(predictions, y)\n",
    "\n",
    "def compute_irm_penalty(params, x, y):\n",
    "    def loss_fn(w_params):\n",
    "        features = feature_extractor.apply(params['phi'], None, x)\n",
    "        predictions = predictor.apply(w_params, None, features)\n",
    "        return mse_loss(predictions, y)\n",
    "    grads = jax.grad(loss_fn)(params['w'])\n",
    "    grad_norm = sum([jnp.sum(jnp.square(g)) for g in jax.tree_leaves(grads)])\n",
    "    return grad_norm\n",
    "\n",
    "def compute_physics_loss(params, x, beta):\n",
    "    \"\"\"\n",
    "    Compute the physics loss term for the underdamped harmonic oscillator.\n",
    "    \"\"\"\n",
    "    def net_output_scalar(t_scalar):\n",
    "        t_scalar = t_scalar.reshape(1, 1)\n",
    "        features = feature_extractor.apply(params['phi'], None, t_scalar)\n",
    "        x_pred = predictor.apply(params['w'], None, features)\n",
    "        return x_pred.squeeze()\n",
    "\n",
    "    # Vectorize net_output_scalar over x\n",
    "    net_output_vec = jax.vmap(net_output_scalar)\n",
    "\n",
    "    # Compute x_pred\n",
    "    x_pred = net_output_vec(x.squeeze())\n",
    "\n",
    "    # Compute first derivative dx/dt\n",
    "    dxdt_fn = jax.grad(net_output_scalar)\n",
    "    dxdt = jax.vmap(dxdt_fn)(x.squeeze())\n",
    "\n",
    "    # Compute second derivative d2x/dt2\n",
    "    d2xdt2_fn = jax.grad(dxdt_fn)\n",
    "    d2xdt2 = jax.vmap(d2xdt2_fn)(x.squeeze())\n",
    "\n",
    "    # Compute the residual of the differential equation\n",
    "    residual = d2xdt2 + 2 * beta * dxdt + omega_0**2 * x_pred\n",
    "\n",
    "    # Compute the mean squared residual (physics loss)\n",
    "    physics_loss = jnp.mean(residual**2)\n",
    "\n",
    "    return physics_loss\n",
    "\n",
    "def compute_initial_condition_loss(params, x0, v0, t0):\n",
    "    \"\"\"\n",
    "    Compute the MSE loss for the initial conditions.\n",
    "    \"\"\"\n",
    "    # Predict displacement at t0\n",
    "    t0 = t0.reshape(1, 1)\n",
    "    features = feature_extractor.apply(params['phi'], None, t0)\n",
    "    x_pred = predictor.apply(params['w'], None, features)\n",
    "    x_pred = x_pred.squeeze()\n",
    "\n",
    "    # Compute dx/dt at t0\n",
    "    def net_output_scalar(t_scalar):\n",
    "        t_scalar = t_scalar.reshape(1, 1)\n",
    "        features = feature_extractor.apply(params['phi'], None, t_scalar)\n",
    "        x_pred = predictor.apply(params['w'], None, features)\n",
    "        return x_pred.squeeze()\n",
    "\n",
    "    dxdt_fn = jax.grad(net_output_scalar)\n",
    "    dxdt_pred = dxdt_fn(t0.squeeze())\n",
    "\n",
    "    # Compute MSE loss for displacement and velocity\n",
    "    displacement_loss = (x_pred - x0) ** 2\n",
    "    velocity_loss = (dxdt_pred - v0) ** 2\n",
    "\n",
    "    ic_loss = displacement_loss + velocity_loss\n",
    "\n",
    "    return ic_loss\n",
    "\n",
    "def total_loss(params, batch_data, lambda_irm, lambda_physics, lambda_ic):\n",
    "    erm_loss = 0.0\n",
    "    irm_penalty = 0.0\n",
    "    physics_loss = 0.0\n",
    "    ic_loss = 0.0\n",
    "\n",
    "    for data in batch_data:\n",
    "        x = data['x']\n",
    "        y = data['y']\n",
    "        beta = data['beta']\n",
    "        x0 = data['x0']\n",
    "        v0 = data['v0']\n",
    "        t0 = x[0]\n",
    "\n",
    "        erm_loss += compute_erm_loss(params, x, y)\n",
    "        irm_penalty += compute_irm_penalty(params, x, y)\n",
    "        physics_loss += compute_physics_loss(params, x, beta)\n",
    "        ic_loss += compute_initial_condition_loss(params, x0, v0, t0)\n",
    "\n",
    "    erm_loss /= len(batch_data)\n",
    "    irm_penalty /= len(batch_data)\n",
    "    physics_loss /= len(batch_data)\n",
    "    ic_loss /= len(batch_data)\n",
    "\n",
    "    total_loss_value = (erm_loss +\n",
    "                        lambda_irm * irm_penalty +\n",
    "                        lambda_physics * physics_loss +\n",
    "                        lambda_ic * ic_loss)\n",
    "\n",
    "    return total_loss_value, (erm_loss, irm_penalty, physics_loss, ic_loss)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50000\n",
    "lambda_irm = 1.0\n",
    "lambda_physics = 1.0\n",
    "lambda_ic = 1.0\n",
    "\n",
    "@jax.jit\n",
    "def update(params, opt_state, batch_data):\n",
    "    (loss_value, (erm_loss, irm_penalty, physics_loss, ic_loss)), grads = jax.value_and_grad(total_loss, has_aux=True)(\n",
    "        params, batch_data, lambda_irm, lambda_physics, lambda_ic)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_value, erm_loss, irm_penalty, physics_loss, ic_loss\n",
    "\n",
    "loss_history = []\n",
    "erm_loss_history = []\n",
    "irm_penalty_history = []\n",
    "physics_loss_history = []\n",
    "ic_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    params, opt_state, loss_value, erm_loss, irm_penalty, physics_loss, ic_loss = update(\n",
    "        params, opt_state, batch_data)\n",
    "    loss_history.append(loss_value)\n",
    "    erm_loss_history.append(erm_loss)\n",
    "    irm_penalty_history.append(irm_penalty)\n",
    "    physics_loss_history.append(physics_loss)\n",
    "    ic_loss_history.append(ic_loss)\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Total Loss: {loss_value:.6f}, \"\n",
    "              f\"ERM Loss: {erm_loss:.6f}, IRM Penalty: {irm_penalty:.6f}, \"\n",
    "              f\"Physics Loss: {physics_loss:.6f}, IC Loss: {ic_loss:.6f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate(params, env_data):\n",
    "    predictions = []\n",
    "    for data in env_data:\n",
    "        x = data['t']\n",
    "        features = feature_extractor.apply(params['phi'], None, x)\n",
    "        y_pred = predictor.apply(params['w'], None, features)\n",
    "        predictions.append(y_pred.flatten())\n",
    "    return predictions\n",
    "\n",
    "predictions = evaluate(params, env_data)\n",
    "\n",
    "# Plot the results\n",
    "for i, data in enumerate(env_data):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(data['t'], data['x'], label='True')\n",
    "    plt.plot(data['t'], predictions[i], label='Predicted')\n",
    "    plt.title(f\"Environment {i+1} (beta={data['beta']})\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Displacement')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
